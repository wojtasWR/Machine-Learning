{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('TrainOnMe.csv')\n",
    "df_val= pd.read_csv('EvaluateOnMe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.89826</td>\n",
       "      <td>-15.49745</td>\n",
       "      <td>0.07850</td>\n",
       "      <td>15.76887</td>\n",
       "      <td>7.09385</td>\n",
       "      <td>Bayesian Inference</td>\n",
       "      <td>-9.45513</td>\n",
       "      <td>-41.74396</td>\n",
       "      <td>-74.87425</td>\n",
       "      <td>5.62655</td>\n",
       "      <td>-20.14669</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Þarf sás þér skal hvarfa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>þengill fyr kné lengi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>(svarar hógliga hverju)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>hugborð (konungr orði);</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>fáir erum vér</td>\n",
       "      <td>né frýju</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>frændr</td>\n",
       "      <td>órum þó vændir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>(minnumk meir á annat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>mitt starf) konungdjarfir.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>438</td>\n",
       "      <td>Atsuto</td>\n",
       "      <td>-20.90675</td>\n",
       "      <td>-15.52179</td>\n",
       "      <td>0.58056</td>\n",
       "      <td>12.19680</td>\n",
       "      <td>3.43925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.72169</td>\n",
       "      <td>-8.09088</td>\n",
       "      <td>-77.73056</td>\n",
       "      <td>8.28782</td>\n",
       "      <td>-20.17833</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>606</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-21.60114</td>\n",
       "      <td>-15.41683</td>\n",
       "      <td>0.36192</td>\n",
       "      <td>4.86373</td>\n",
       "      <td>-1.77810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.30774</td>\n",
       "      <td>1.74038</td>\n",
       "      <td>-78.53296</td>\n",
       "      <td>7.62748</td>\n",
       "      <td>-20.04187</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.43997</td>\n",
       "      <td>-15.44248</td>\n",
       "      <td>0.17758</td>\n",
       "      <td>28.56231</td>\n",
       "      <td>4.05485</td>\n",
       "      <td>Bayesian Inference</td>\n",
       "      <td>-2.04917</td>\n",
       "      <td>3.64082</td>\n",
       "      <td>-78.78604</td>\n",
       "      <td>10.53454</td>\n",
       "      <td>-20.07523</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-34.50822</td>\n",
       "      <td>-15.44613</td>\n",
       "      <td>0.81278</td>\n",
       "      <td>19.22793</td>\n",
       "      <td>7.02529</td>\n",
       "      <td>Bayesian Inference</td>\n",
       "      <td>-16.41150</td>\n",
       "      <td>45.73634</td>\n",
       "      <td>-80.30337</td>\n",
       "      <td>10.13587</td>\n",
       "      <td>-20.07997</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Unnamed: 0                y        x1        x2  \\\n",
       "173                          173              NaN  -5.89826 -15.49745   \n",
       "258     Þarf sás þér skal hvarfa              NaN       NaN       NaN   \n",
       "259        þengill fyr kné lengi              NaN       NaN       NaN   \n",
       "260      (svarar hógliga hverju)              NaN       NaN       NaN   \n",
       "261      hugborð (konungr orði);              NaN       NaN       NaN   \n",
       "262                fáir erum vér         né frýju       NaN       NaN   \n",
       "263                       frændr   órum þó vændir       NaN       NaN   \n",
       "264        (minnumk meir á annat              NaN       NaN       NaN   \n",
       "265   mitt starf) konungdjarfir.              NaN       NaN       NaN   \n",
       "446                          438           Atsuto -20.90675 -15.52179   \n",
       "614                          606              Bob -21.60114 -15.41683   \n",
       "704                          696              NaN -13.43997 -15.44248   \n",
       "1000                         992              NaN -34.50822 -15.44613   \n",
       "\n",
       "           x3        x4       x5                  x6        x7        x8  \\\n",
       "173   0.07850  15.76887  7.09385  Bayesian Inference  -9.45513 -41.74396   \n",
       "258       NaN       NaN      NaN                 NaN       NaN       NaN   \n",
       "259       NaN       NaN      NaN                 NaN       NaN       NaN   \n",
       "260       NaN       NaN      NaN                 NaN       NaN       NaN   \n",
       "261       NaN       NaN      NaN                 NaN       NaN       NaN   \n",
       "262       NaN       NaN      NaN                 NaN       NaN       NaN   \n",
       "263       NaN       NaN      NaN                 NaN       NaN       NaN   \n",
       "264       NaN       NaN      NaN                 NaN       NaN       NaN   \n",
       "265       NaN       NaN      NaN                 NaN       NaN       NaN   \n",
       "446   0.58056  12.19680  3.43925                 NaN  -5.72169  -8.09088   \n",
       "614   0.36192   4.86373 -1.77810                 NaN  -6.30774   1.74038   \n",
       "704   0.17758  28.56231  4.05485  Bayesian Inference  -2.04917   3.64082   \n",
       "1000  0.81278  19.22793  7.02529  Bayesian Inference -16.41150  45.73634   \n",
       "\n",
       "            x9       x10       x11    x12  \n",
       "173  -74.87425   5.62655 -20.14669  False  \n",
       "258        NaN       NaN       NaN    NaN  \n",
       "259        NaN       NaN       NaN    NaN  \n",
       "260        NaN       NaN       NaN    NaN  \n",
       "261        NaN       NaN       NaN    NaN  \n",
       "262        NaN       NaN       NaN    NaN  \n",
       "263        NaN       NaN       NaN    NaN  \n",
       "264        NaN       NaN       NaN    NaN  \n",
       "265        NaN       NaN       NaN    NaN  \n",
       "446  -77.73056   8.28782 -20.17833  False  \n",
       "614  -78.53296   7.62748 -20.04187  False  \n",
       "704  -78.78604  10.53454 -20.07523  False  \n",
       "1000 -80.30337  10.13587 -20.07997  False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows=df[df.isna().any(axis=1)]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero_nan=df.drop([173,258,259,260,261,262,263,264,265,704,1000,742,830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grabbar = df_zero_nan['y'] #Grabbarna that we want to classify!\n",
    "df_reduced =df_zero_nan.drop(columns=['y']) #reduced contains all the variables without the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy to avoid changing original data \n",
    "\n",
    "label_Y = Grabbar.copy()\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(['Atsuto','Bob','Jorg','Shoogee'])\n",
    "list(label_encoder.classes_)\n",
    "label_y = label_encoder.transform(label_Y)\n",
    "label_y_df = pd.DataFrame(label_y, columns = ['Grabbar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first=df_reduced.drop(columns=['x6','x12','Unnamed: 0'])\n",
    "df_val_last=df_val.drop(columns=['x6','x12','Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = []\n",
    "classification_models.append(('Random Forest', RandomForestClassifier(n_estimators=200, criterion=\"entropy\",random_state=0)))#random_state=0\n",
    "classification_models.append(('GaussianNaiveBayes',GaussianNB()))\n",
    "classification_models.append(('SupportVectorMachineClassifier',SVC(kernel='rbf')))\n",
    "classification_models.append(('KNN',KNeighborsClassifier(n_neighbors=15)))\n",
    "classification_models.append(('XGboost',XGBClassifier()))\n",
    "classification_models.append(('GradientBoostingClassifier',GradientBoostingClassifier()))\n",
    "classification_models.append(('LogisticRegression',LogisticRegression(multi_class='multinomial')))\n",
    "classification_models.append(('QuadraticDA',QuadraticDiscriminantAnalysis()))#priors=[0.1, 0.3, 0.2, 0.5]\n",
    "classification_models.append(('LinearcDA',LinearDiscriminantAnalysis()))\n",
    "classification_models.append(('DecisionTreeClassifier', DecisionTreeClassifier(criterion=\"entropy\",random_state=0)))\n",
    "classification_models.append(('BaggingClassifier', BaggingClassifier()))\n",
    "classification_models.append(('MLPClassifier', MLPClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(classification_models,X,Y):\n",
    "    for i,v in classification_models:\n",
    "        clf=v\n",
    "        scores = cross_val_score(clf, X, Y, cv=5, verbose=1)\n",
    "        print(i)\n",
    "        print(scores)\n",
    "        print(\"Score: %0.3f +- %0.3f\" % (scores.mean(), scores.std()))\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "[0.71859296 0.71356784 0.69346734 0.73869347 0.74371859]\n",
      "Score: 0.722 +- 0.018\n",
      "GaussianNaiveBayes\n",
      "[0.64824121 0.62311558 0.67336683 0.61809045 0.64824121]\n",
      "Score: 0.642 +- 0.020\n",
      "SupportVectorMachineClassifier\n",
      "[0.54271357 0.57286432 0.50251256 0.51256281 0.53768844]\n",
      "Score: 0.534 +- 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "[0.55778894 0.6281407  0.53768844 0.57286432 0.61809045]\n",
      "Score: 0.583 +- 0.035\n",
      "[16:46:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost\n",
      "[0.72864322 0.73366834 0.67839196 0.69849246 0.72864322]\n",
      "Score: 0.714 +- 0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "[0.75376884 0.72361809 0.66834171 0.66331658 0.71356784]\n",
      "Score: 0.705 +- 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "[0.54271357 0.51758794 0.5678392  0.59798995 0.53768844]\n",
      "Score: 0.553 +- 0.028\n",
      "QuadraticDA\n",
      "[0.73869347 0.72361809 0.71859296 0.74371859 0.77889447]\n",
      "Score: 0.741 +- 0.021\n",
      "LinearcDA\n",
      "[0.53266332 0.59798995 0.59798995 0.59296482 0.53266332]\n",
      "Score: 0.571 +- 0.031\n",
      "DecisionTreeClassifier\n",
      "[0.65829146 0.66331658 0.65326633 0.64824121 0.68844221]\n",
      "Score: 0.662 +- 0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "[0.69346734 0.69346734 0.65829146 0.70351759 0.69346734]\n",
      "Score: 0.688 +- 0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "[0.66834171 0.60301508 0.61306533 0.61306533 0.70854271]\n",
      "Score: 0.641 +- 0.041\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "print(score(classification_models,df_first,label_y_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "X_train=scaler.fit_transform(df_first)\n",
    "X_val=scaler.transform(df_val_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "[0.71859296 0.71356784 0.69346734 0.73869347 0.74371859]\n",
      "Score: 0.722 +- 0.018\n",
      "GaussianNaiveBayes\n",
      "[0.64824121 0.62311558 0.67336683 0.61809045 0.64824121]\n",
      "Score: 0.642 +- 0.020\n",
      "SupportVectorMachineClassifier\n",
      "[0.71356784 0.68341709 0.71859296 0.70854271 0.72864322]\n",
      "Score: 0.711 +- 0.015\n",
      "KNN\n",
      "[0.65326633 0.68844221 0.65326633 0.67839196 0.67839196]\n",
      "Score: 0.670 +- 0.014\n",
      "[16:47:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:47:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:47:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:47:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:47:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost\n",
      "[0.72864322 0.73366834 0.67839196 0.69849246 0.72864322]\n",
      "Score: 0.714 +- 0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "[0.75376884 0.72361809 0.66331658 0.68844221 0.71356784]\n",
      "Score: 0.709 +- 0.031\n",
      "LogisticRegression\n",
      "[0.54773869 0.57788945 0.59296482 0.59798995 0.53768844]\n",
      "Score: 0.571 +- 0.024\n",
      "QuadraticDA\n",
      "[0.73869347 0.72361809 0.71859296 0.74371859 0.77889447]\n",
      "Score: 0.741 +- 0.021\n",
      "LinearcDA\n",
      "[0.53266332 0.59798995 0.59798995 0.59296482 0.53266332]\n",
      "Score: 0.571 +- 0.031\n",
      "DecisionTreeClassifier\n",
      "[0.65829146 0.66331658 0.65326633 0.64824121 0.68844221]\n",
      "Score: 0.662 +- 0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "[0.71859296 0.66834171 0.66834171 0.71356784 0.69346734]\n",
      "Score: 0.692 +- 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "[0.74371859 0.69849246 0.69849246 0.69849246 0.76884422]\n",
      "Score: 0.722 +- 0.029\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "print(score(classification_models,X_train,label_y_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.756 +- 0.029\n",
      "[0.77889447 0.71859296 0.72361809 0.76884422 0.78894472]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "estimators = [('rf', RandomForestClassifier(n_estimators=200,criterion=\"entropy\", random_state=0)),('svr',SVC(kernel='rbf', decision_function_shape='ovr', break_ties=True, C=1.65, probability=True)),('quadraticDA',QuadraticDiscriminantAnalysis()),('MLPClassifier',MLPClassifier()),('xgboost',XGBClassifier(n_estimators=1000, verbosity=0))]#,('Knn',KNeighborsClassifier(n_neighbors=5, weights='distance')),(\"MLP\",MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100), activation=\"relu\", solver=\"lbfgs\")),('Logisticreg',LogisticRegression(max_iter=1000)),(\"ExtraTree\",ExtraTreesClassifier(n_estimators=1000, max_depth=None))]\n",
    "clf2 = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "scores2 = cross_val_score(clf2, X_train, label_y_df, cv=5, verbose=1)\n",
    "print(\"Score: %0.3f +- %0.3f\" % (scores2.mean(), scores2.std()))\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,X,Y,X_val):\n",
    "    clf=model\n",
    "    clf.fit(X, Y)\n",
    "    prediction=clf.predict(X_val)\n",
    "    #Y_test_prediction=Y_test.to_numpy()\n",
    "    #Y_test_prediction = np.concatenate( Y_test_prediction, axis=0)\n",
    "    res2=label_encoder.inverse_transform(prediction)\n",
    "    print(str(model))\n",
    "    print('Shoogee')\n",
    "    print(list(res2).count('Shoogee'))\n",
    "    print('Atsuto')\n",
    "    print(list(res2).count('Atsuto'))\n",
    "    print('Bob')\n",
    "    print(list(res2).count('Bob'))\n",
    "    print('Jorg')\n",
    "    print(list(res2).count('Jorg'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticDiscriminantAnalysis()\n",
      "Shoogee\n",
      "1018\n",
      "Atsuto\n",
      "3260\n",
      "Bob\n",
      "3981\n",
      "Jorg\n",
      "1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "evaluate(QuadraticDiscriminantAnalysis(),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-e79ecaf1b3cc>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', n_estimators=200, random_state=0)\n",
      "Shoogee\n",
      "929\n",
      "Atsuto\n",
      "3613\n",
      "Bob\n",
      "3540\n",
      "Jorg\n",
      "1918\n"
     ]
    }
   ],
   "source": [
    "evaluate(RandomForestClassifier(n_estimators=200, criterion=\"entropy\",random_state=0),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "Shoogee\n",
      "897\n",
      "Atsuto\n",
      "3978\n",
      "Bob\n",
      "3692\n",
      "Jorg\n",
      "1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "evaluate(SVC(kernel='rbf'),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier()\n",
      "Shoogee\n",
      "1004\n",
      "Atsuto\n",
      "3416\n",
      "Bob\n",
      "3676\n",
      "Jorg\n",
      "1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate(MLPClassifier(),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Shoogee\n",
      "1013\n",
      "Atsuto\n",
      "3644\n",
      "Bob\n",
      "3372\n",
      "Jorg\n",
      "1971\n"
     ]
    }
   ],
   "source": [
    "evaluate(XGBClassifier(),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticDiscriminantAnalysis()\n",
      "Shoogee\n",
      "1018\n",
      "Atsuto\n",
      "3260\n",
      "Bob\n",
      "3981\n",
      "Jorg\n",
      "1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "evaluate(QuadraticDiscriminantAnalysis(),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier(estimators=[('rf',\n",
      "                                RandomForestClassifier(criterion='entropy',\n",
      "                                                       n_estimators=200,\n",
      "                                                       random_state=0)),\n",
      "                               ('svr',\n",
      "                                SVC(C=1.65, break_ties=True, probability=True)),\n",
      "                               ('quadraticDA', QuadraticDiscriminantAnalysis()),\n",
      "                               ('MLPClassifier', MLPClassifier()),\n",
      "                               ('xgboost',\n",
      "                                XGBClassifier(base_score=None, booster=None,\n",
      "                                              colsample_bylevel=None,\n",
      "                                              colsample_bynode=None,\n",
      "                                              co...\n",
      "                                              interaction_constraints=None,\n",
      "                                              learning_rate=None,\n",
      "                                              max_delta_step=None,\n",
      "                                              max_depth=None,\n",
      "                                              min_child_weight=None,\n",
      "                                              missing=nan,\n",
      "                                              monotone_constraints=None,\n",
      "                                              n_estimators=1000, n_jobs=None,\n",
      "                                              num_parallel_tree=None,\n",
      "                                              random_state=None, reg_alpha=None,\n",
      "                                              reg_lambda=None,\n",
      "                                              scale_pos_weight=None,\n",
      "                                              subsample=None, tree_method=None,\n",
      "                                              validate_parameters=None,\n",
      "                                              verbosity=0))],\n",
      "                   final_estimator=LogisticRegression())\n",
      "Shoogee\n",
      "1004\n",
      "Atsuto\n",
      "3478\n",
      "Bob\n",
      "3632\n",
      "Jorg\n",
      "1886\n"
     ]
    }
   ],
   "source": [
    "evaluate(StackingClassifier(estimators=estimators, final_estimator=LogisticRegression()),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier(estimators=[('rf',\n",
      "                                RandomForestClassifier(criterion='entropy',\n",
      "                                                       n_estimators=200,\n",
      "                                                       random_state=0)),\n",
      "                               ('svr',\n",
      "                                SVC(C=1.65, break_ties=True, probability=True)),\n",
      "                               ('quadraticDA', QuadraticDiscriminantAnalysis()),\n",
      "                               ('MLPClassifier', MLPClassifier()),\n",
      "                               ('xgboost',\n",
      "                                XGBClassifier(base_score=None, booster=None,\n",
      "                                              colsample_bylevel=None,\n",
      "                                              colsample_bynode=None,\n",
      "                                              co...\n",
      "                                              interaction_constraints=None,\n",
      "                                              learning_rate=None,\n",
      "                                              max_delta_step=None,\n",
      "                                              max_depth=None,\n",
      "                                              min_child_weight=None,\n",
      "                                              missing=nan,\n",
      "                                              monotone_constraints=None,\n",
      "                                              n_estimators=1000, n_jobs=None,\n",
      "                                              num_parallel_tree=None,\n",
      "                                              random_state=None, reg_alpha=None,\n",
      "                                              reg_lambda=None,\n",
      "                                              scale_pos_weight=None,\n",
      "                                              subsample=None, tree_method=None,\n",
      "                                              validate_parameters=None,\n",
      "                                              verbosity=0))],\n",
      "                   final_estimator=LogisticRegression())\n",
      "Shoogee\n",
      "1004\n",
      "Atsuto\n",
      "3393\n",
      "Bob\n",
      "3728\n",
      "Jorg\n",
      "1875\n"
     ]
    }
   ],
   "source": [
    "evaluate(StackingClassifier(estimators=estimators, final_estimator=LogisticRegression()),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier(estimators=[('rf',\n",
      "                                RandomForestClassifier(criterion='entropy',\n",
      "                                                       n_estimators=200,\n",
      "                                                       random_state=0)),\n",
      "                               ('svr',\n",
      "                                SVC(C=1.65, break_ties=True, probability=True)),\n",
      "                               ('quadraticDA', QuadraticDiscriminantAnalysis()),\n",
      "                               ('MLPClassifier', MLPClassifier()),\n",
      "                               ('xgboost',\n",
      "                                XGBClassifier(base_score=None, booster=None,\n",
      "                                              colsample_bylevel=None,\n",
      "                                              colsample_bynode=None,\n",
      "                                              co...\n",
      "                                              interaction_constraints=None,\n",
      "                                              learning_rate=None,\n",
      "                                              max_delta_step=None,\n",
      "                                              max_depth=None,\n",
      "                                              min_child_weight=None,\n",
      "                                              missing=nan,\n",
      "                                              monotone_constraints=None,\n",
      "                                              n_estimators=1000, n_jobs=None,\n",
      "                                              num_parallel_tree=None,\n",
      "                                              random_state=None, reg_alpha=None,\n",
      "                                              reg_lambda=None,\n",
      "                                              scale_pos_weight=None,\n",
      "                                              subsample=None, tree_method=None,\n",
      "                                              validate_parameters=None,\n",
      "                                              verbosity=0))],\n",
      "                   final_estimator=LogisticRegression())\n",
      "Shoogee\n",
      "1003\n",
      "Atsuto\n",
      "3437\n",
      "Bob\n",
      "3656\n",
      "Jorg\n",
      "1904\n"
     ]
    }
   ],
   "source": [
    "evaluate(StackingClassifier(estimators=estimators, final_estimator=LogisticRegression()),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier(estimators=[('rf',\n",
      "                                RandomForestClassifier(criterion='entropy',\n",
      "                                                       n_estimators=200,\n",
      "                                                       random_state=0)),\n",
      "                               ('svr',\n",
      "                                SVC(C=1.65, break_ties=True, probability=True)),\n",
      "                               ('quadraticDA', QuadraticDiscriminantAnalysis()),\n",
      "                               ('MLPClassifier', MLPClassifier()),\n",
      "                               ('xgboost',\n",
      "                                XGBClassifier(base_score=None, booster=None,\n",
      "                                              colsample_bylevel=None,\n",
      "                                              colsample_bynode=None,\n",
      "                                              co...\n",
      "                                              interaction_constraints=None,\n",
      "                                              learning_rate=None,\n",
      "                                              max_delta_step=None,\n",
      "                                              max_depth=None,\n",
      "                                              min_child_weight=None,\n",
      "                                              missing=nan,\n",
      "                                              monotone_constraints=None,\n",
      "                                              n_estimators=1000, n_jobs=None,\n",
      "                                              num_parallel_tree=None,\n",
      "                                              random_state=None, reg_alpha=None,\n",
      "                                              reg_lambda=None,\n",
      "                                              scale_pos_weight=None,\n",
      "                                              subsample=None, tree_method=None,\n",
      "                                              validate_parameters=None,\n",
      "                                              verbosity=0))],\n",
      "                   final_estimator=LogisticRegression())\n",
      "Shoogee\n",
      "1003\n",
      "Atsuto\n",
      "3440\n",
      "Bob\n",
      "3667\n",
      "Jorg\n",
      "1890\n"
     ]
    }
   ],
   "source": [
    "evaluate(StackingClassifier(estimators=estimators, final_estimator=LogisticRegression()),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2(model,X,Y,X_val):\n",
    "    clf=model\n",
    "    clf.fit(X, Y)\n",
    "    prediction=clf.predict(X_val)\n",
    "    res2=label_encoder.inverse_transform(prediction)\n",
    "    return res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/wojtasratusznik/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "hello=evaluate2(StackingClassifier(estimators=estimators, final_estimator=LogisticRegression()),X_train,label_y_df,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista=list(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3673"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista.count('Bob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3442"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista.count('Atsuto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista.count('Shoogee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1885"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista.count('Jorg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bob        367\n",
       "Atsuto     331\n",
       "Jorg       209\n",
       "Shoogee     88\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grabbar.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shoogee',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Shoogee',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Jorg',\n",
       " 'Atsuto',\n",
       " 'Bob',\n",
       " 'Bob',\n",
       " 'Atsuto',\n",
       " 'Atsuto',\n",
       " 'Shoogee',\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('WojciechRatusznik_pred.txt','w')\n",
    "for ele in lista:\n",
    "    f.write(ele+'\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
